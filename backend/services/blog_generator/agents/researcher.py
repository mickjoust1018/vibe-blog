"""
Researcher Agent - ç´ ææ”¶é›†
"""

import json
import logging
from typing import Dict, Any, List, Optional

from ..prompts.prompt_manager import get_prompt_manager

logger = logging.getLogger(__name__)


class ResearcherAgent:
    """
    ä¸»é¢˜ç´ ææ”¶é›†å¸ˆ - è´Ÿè´£è”ç½‘æœç´¢æ”¶é›†èƒŒæ™¯èµ„æ–™
    æ”¯æŒæ–‡æ¡£çŸ¥è¯†èåˆï¼ˆä¸€æœŸï¼‰
    """
    
    def __init__(self, llm_client, search_service=None, knowledge_service=None):
        """
        åˆå§‹åŒ– Researcher Agent
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            search_service: æœç´¢æœåŠ¡ (å¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™è·³è¿‡æœç´¢)
            knowledge_service: çŸ¥è¯†æœåŠ¡ (å¯é€‰ï¼Œç”¨äºæ–‡æ¡£çŸ¥è¯†èåˆ)
        """
        self.llm = llm_client
        self.search_service = search_service
        self.knowledge_service = knowledge_service
    
    def generate_search_queries(self, topic: str, target_audience: str) -> List[str]:
        """
        ç”Ÿæˆæœç´¢æŸ¥è¯¢
        
        Args:
            topic: æŠ€æœ¯ä¸»é¢˜
            target_audience: ç›®æ ‡å—ä¼—
            
        Returns:
            æœç´¢æŸ¥è¯¢åˆ—è¡¨
        """
        # é»˜è®¤æœç´¢ç­–ç•¥
        default_queries = [
            f"{topic} æ•™ç¨‹ tutorial",
            f"{topic} æœ€ä½³å®è·µ best practices",
            f"{topic} å¸¸è§é—®é¢˜ FAQ",
        ]
        
        if not self.llm:
            return default_queries
        
        try:
            pm = get_prompt_manager()
            prompt = pm.render_search_query(
                topic=topic,
                target_audience=target_audience
            )
            
            response = self.llm.chat(
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            
            queries = json.loads(response)
            if isinstance(queries, list):
                return queries
            return default_queries
            
        except Exception as e:
            logger.warning(f"ç”Ÿæˆæœç´¢æŸ¥è¯¢å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æŸ¥è¯¢")
            return default_queries
    
    def search(self, topic: str, target_audience: str, max_results: int = 10) -> List[Dict]:
        """
        æ‰§è¡Œæœç´¢
        
        Args:
            topic: æŠ€æœ¯ä¸»é¢˜
            target_audience: ç›®æ ‡å—ä¼—
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.search_service:
            logger.warning("æœç´¢æœåŠ¡æœªé…ç½®ï¼Œè·³è¿‡æœç´¢")
            return []
        
        queries = self.generate_search_queries(topic, target_audience)
        all_results = []
        
        for query in queries:
            try:
                result = self.search_service.search(query, max_results=max_results // len(queries))
                if result.get('success') and result.get('results'):
                    all_results.extend(result['results'])
            except Exception as e:
                logger.error(f"æœç´¢å¤±è´¥ [{query}]: {e}")
        
        # å»é‡
        seen_urls = set()
        unique_results = []
        for item in all_results:
            url = item.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(item)
        
        return unique_results[:max_results]
    
    def summarize(
        self,
        topic: str,
        search_results: List[Dict],
        target_audience: str,
        search_depth: str = "medium"
    ) -> Dict[str, Any]:
        """
        æ•´ç†æœç´¢ç»“æœï¼Œç”ŸæˆèƒŒæ™¯çŸ¥è¯†æ‘˜è¦
        
        Args:
            topic: æŠ€æœ¯ä¸»é¢˜
            search_results: æœç´¢ç»“æœ
            target_audience: ç›®æ ‡å—ä¼—
            search_depth: æœç´¢æ·±åº¦
            
        Returns:
            æ•´ç†åçš„ç»“æœ
        """
        if not search_results:
            return {
                "background_knowledge": f"å…³äº {topic} çš„èƒŒæ™¯çŸ¥è¯†å°†åœ¨åç»­ç« èŠ‚ä¸­è¯¦ç»†ä»‹ç»ã€‚",
                "key_concepts": [],
                "top_references": []
            }
        
        pm = get_prompt_manager()
        prompt = pm.render_researcher(
            topic=topic,
            search_depth=search_depth,
            target_audience=target_audience,
            search_results=search_results[:10]
        )
        
        try:
            response = self.llm.chat(
                messages=[{"role": "user", "content": prompt}]
            )
            
            # æå– JSONï¼ˆå¤„ç† markdown ä»£ç å—ï¼‰
            json_str = response
            if '```json' in response:
                json_str = response.split('```json')[1].split('```')[0].strip()
            elif '```' in response:
                json_str = response.split('```')[1].split('```')[0].strip()
            
            # å°è¯•è§£æ JSON
            result = json.loads(json_str)
            key_concepts = result.get("key_concepts", [])
            
            # è°ƒè¯•ï¼šæ‰“å°å®é™…è¿”å›å†…å®¹
            logger.info(f"LLM è¿”å› key_concepts ç±»å‹: {type(key_concepts)}, å€¼: {key_concepts}")
            
            # å¦‚æœ key_concepts ä¸ºç©ºä½†æœ‰å…¶ä»–å¯èƒ½çš„å­—æ®µå
            if not key_concepts:
                # å°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µå
                for alt_key in ['keyConcepts', 'concepts', 'core_concepts', 'keywords']:
                    if result.get(alt_key):
                        key_concepts = result.get(alt_key)
                        logger.info(f"ä½¿ç”¨å¤‡é€‰å­—æ®µ {alt_key}: {key_concepts}")
                        break
            
            if key_concepts:
                logger.info(f"æ ¸å¿ƒæ¦‚å¿µ: {[c.get('name', c) if isinstance(c, dict) else c for c in key_concepts[:5]]}")
            
            return {
                "background_knowledge": result.get("background_knowledge", ""),
                "key_concepts": key_concepts,
                "top_references": result.get("top_references", [])
            }
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}, å“åº”å†…å®¹: {response[:500] if response else 'None'}")
        except Exception as e:
            logger.error(f"æ•´ç†æœç´¢ç»“æœå¤±è´¥: {e}")
        
        # è¿”å›ç®€å•æ‘˜è¦
        return {
            "background_knowledge": '\n'.join([
                item.get('content', '')[:200] for item in search_results[:3]
            ]),
            "key_concepts": [],
            "top_references": [
                {"title": item.get('title', ''), "url": item.get('url', '')}
                    for item in search_results[:5]
                ]
            }
    
    def run(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œç´ ææ”¶é›†
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. æ— æ–‡æ¡£ä¸Šä¼  â†’ åŸæœ‰æµç¨‹ï¼ˆä»…ç½‘ç»œæœç´¢ï¼‰
        2. æœ‰æ–‡æ¡£ä¸Šä¼  â†’ çŸ¥è¯†èåˆæµç¨‹ï¼ˆæ–‡æ¡£ + ç½‘ç»œæœç´¢ï¼‰
        
        Args:
            state: å…±äº«çŠ¶æ€
            
        Returns:
            æ›´æ–°åçš„çŠ¶æ€
        """
        topic = state.get('topic', '')
        target_audience = state.get('target_audience', 'intermediate')
        
        # è·å–æ–‡æ¡£çŸ¥è¯†ï¼ˆå¦‚æœæœ‰ä¸Šä¼ æ–‡æ¡£ï¼‰
        document_knowledge = state.get('document_knowledge', [])
        has_document = bool(document_knowledge)
        
        logger.info(f"ğŸ” å¼€å§‹æ”¶é›†ç´ æ: {topic}")
        logger.info(f"ğŸ“„ ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£çŸ¥è¯†: {len(document_knowledge)} æ¡")
        
        # 1. æ‰§è¡Œç½‘ç»œæœç´¢ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        logger.info(f"ğŸŒ å¯åŠ¨ç½‘ç»œæœç´¢...")
        search_results = self.search(topic, target_audience)
        
        # 2. çŸ¥è¯†èåˆåˆ†æ”¯
        if self.knowledge_service and has_document:
            # âœ… æœ‰æ–‡æ¡£ â†’ èµ°çŸ¥è¯†èåˆé€»è¾‘
            logger.info("ä½¿ç”¨çŸ¥è¯†èåˆæ¨¡å¼")
            
            # å°†æ–‡æ¡£çŸ¥è¯†è½¬æ¢ä¸º KnowledgeItem
            doc_items = self.knowledge_service.prepare_document_knowledge(
                [{'filename': d.get('file_name', ''), 'markdown_content': d.get('content', '')} 
                 for d in document_knowledge]
            )
            
            # å°†æœç´¢ç»“æœè½¬æ¢ä¸º KnowledgeItem
            web_items = self.knowledge_service.convert_search_results(search_results)
            
            # èåˆçŸ¥è¯†
            merged_knowledge = self.knowledge_service.get_merged_knowledge(
                document_knowledge=doc_items,
                web_knowledge=web_items
            )
            
            # æ•´ç†ä¸º Prompt å¯ç”¨æ ¼å¼
            summary = self.knowledge_service.summarize_for_prompt(merged_knowledge)
            
            # è®°å½•çŸ¥è¯†æ¥æºç»Ÿè®¡
            state['knowledge_source_stats'] = {
                'document_count': len([k for k in merged_knowledge if k.source_type == 'document']),
                'web_count': len([k for k in merged_knowledge if k.source_type == 'web_search']),
                'total_items': len(merged_knowledge)
            }
            state['document_references'] = summary.get('document_references', [])
            
        else:
            # âœ… æ— æ–‡æ¡£ â†’ å®Œå…¨èµ°åŸæœ‰é€»è¾‘ï¼Œé›¶æ”¹åŠ¨
            logger.info("ğŸ“‹ ä½¿ç”¨åŸæœ‰æœç´¢æ¨¡å¼ï¼ˆæ— æ–‡æ¡£ä¸Šä¼ ï¼‰")
            logger.info(f"ğŸ“‹ å°†ä½¿ç”¨ç½‘ç»œæœç´¢ç»“æœç”Ÿæˆåšå®¢å†…å®¹")
            summary = self.summarize(
                topic=topic,
                search_results=search_results,
                target_audience=target_audience
            )
            state['knowledge_source_stats'] = {
                'document_count': 0,
                'web_count': len(search_results),
                'total_items': len(search_results)
            }
            state['document_references'] = []
        
        # 3. æ›´æ–°çŠ¶æ€
        state['search_results'] = search_results
        state['background_knowledge'] = summary.get('background_knowledge', '')
        state['key_concepts'] = [
            c.get('name', c) if isinstance(c, dict) else c
            for c in summary.get('key_concepts', [])
        ]
        state['reference_links'] = [
            r.get('url', r) if isinstance(r, dict) else r
            for r in summary.get('top_references', summary.get('web_references', []))
        ]
        
        stats = state['knowledge_source_stats']
        logger.info(f"âœ… ç´ ææ”¶é›†å®Œæˆ: æ–‡æ¡£çŸ¥è¯† {stats['document_count']} æ¡, "
                    f"ç½‘ç»œæœç´¢ {stats['web_count']} æ¡, æ ¸å¿ƒæ¦‚å¿µ {len(state['key_concepts'])} ä¸ª")
        
        return state
